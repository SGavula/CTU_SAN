---
title: "SAN prerequisites -- hypothesis testing, t-test"
output: html_document
date: "2024-09-23"
---

```{r libs, include=FALSE}
library(ggplot2)
library(extraDistr)
```
# Statistical inference from small samples

This notebook summarizes the most important steps in inference from small samples, where t-test can frequently be applied. The notebook will demonstrate how to do hypothesis tests about sample means and which factors influence their outcome. We will be operating in the domain of blood pressure-lowering medications, and we will be interested in how well each drug meets our expectations.

## Does conventional blood pressure treatment work?

Conventional blood pressure treatment results in stable pressure values represented by the sample of 10 different patients shown below. Decide whether the treatment is adequate, given that the goal is to achieve a mean pressure of no more than 95.

```{r introduce conventional treatment}
cgroup <- c(90,95,67,120,89,92,100,82,79,85)
max_target_mean <- 95

# mean blood pressure is smaller than the desired value
paste("Mean blood pressure and standard deviation in the conventional treatment sample:", mean(cgroup), "and", round(sd(cgroup),2))
```

The mean blood pressure $\bar{x}_c$ calculated from the sample is lower than the desired value. However, since it is a random variable, we need to determine how often it will fall below 95 when sampling repeatedly. We can proceed in two ways: to employ hypothesis testing or calculate confidence intervals. The key parameters will be the standard deviation of the sample $s_c$ and the sample size $n_c$.

Before we do so, there is a couple of basic observations and assumptions: 1) we deal with a small sample (the most common small/large sample size threshold is 30), 2) we may assume that blood pressure is normally distributed (a commonly known medical fact), 3) the measurements are independent (see the design of the study mentioned above), 4) blood pressure variance in our population is unknown (and we will have to estimate it from the sample). 

Consequently, we will approximate the distribution of sample means with t-distribution. We will plot it, run the hypothesis test and compute the 95% sample mean confidence interval.

<!--  We would either need a large sample or known population variance to be able to deal with a bit simpler normal distribution and z-test. If the population has an arbitrary distribution we definitely need a large sample to be able to deal with the normal distribution. This reasoning makes t-test one of the most frequent statistical tests. -->

### Hypothesis testing, one-sample t-test

```{r conventional treatment t-test}
c_mean <- mean(cgroup)
c_sd <- sd(cgroup)

# call the one-sided t-test
t.test(x=cgroup,alternative="less",mu=max_target_mean)

# Let us reach the same outcomes slower:
m_sd <- c_sd/sqrt(length(cgroup))
t.value <- (c_mean-max_target_mean)/m_sd
# use the distribution function of t-distribution with 9 degrees of freedom to obtain p-value
paste("P-value of one-sided t-test:", round(pt(t.value,df=9,lower.tail=T),2))
```

<!--  Notice that we encounter two different distributions. The first one is pressure distribution in the treated population. We have already agreed that the population can be described with the normal distribution, its parameters are unknown, $N(\mu_c,\sigma^2_c)$. The sample mean $\bar{x}_c$ and variance $s^2_c$ can serve as unbiased estimates of the population parameters. The second one is the distribution of sample means. When repeating sampling, sample means will follow the t-distribution  $t(n_c-1,\bar{x}_c,s^2_c/n)$. -->

We performed the one-sided t-test with $H_0$: "the population mean is 95, i.e., $\mu_c=95$" and $H_a$: "the population mean is smaller than 95, i.e., $\mu_c<95$". We employed the formula: $$t_c=\frac{\bar{x}_c-\mu}{s_c/\sqrt{n_c}}=\frac{89.9-95}{14.02/\sqrt{10}}=-1.15$$

where $\bar{x}_c$ is the sample mean, $\mu$ is the (desired) population mean, $s_c$ is the sample standard deviation and $n_c$ is the sample size. In terms of hypothesis testing, the value of t-statistic is compared with the quantiles of standardized t-distribution with $n_c-1$ degrees of freedom. 

The p-value is 0.14. If we choose a common level of significance $\alpha=0.05$, we can see that $p>\alpha$. We cannot reject the null hypothesis. We failed to confirm the initial goal statistically. The p-value of 0.14 suggests that there is a 14% probability of observing a sample like ours, or one even more extreme, by chance if the null hypothesis holds. Consequently, we **cannot reject the null hypothesis** in favor of the alternative hypothesis.

```{r conventional treatment explanatory pdf plot, echo=FALSE}
# t-distribution probability density function, n-1 degrees of freedom, the mean is set to match the null hypothesis, the standard deviation is estimated from the sample
# normal distribution added for illustration
t.values <- seq(max_target_mean-15,max_target_mean+15,0.2)
dft9 <- data.frame(t.values,dn=dnorm(t.values,mean=max_target_mean,sd=c_sd/sqrt(length(cgroup))),dt9=dlst(t.values,df=length(cgroup)-1,mu=max_target_mean,sigma=c_sd/sqrt(length(cgroup))))

# use the observed sample mean and standard deviation and plot
ggplot(dft9, aes(x = t.values)) + 
  geom_line(aes(y = dt9, color="t_dist")) +
  geom_line(aes(y = dn, color="normal"), linetype="dotted") +
  geom_vline(xintercept = mean(cgroup), colour="blue", linetype="dashed") +
  geom_vline(xintercept = max_target_mean, colour="red", linetype="dashed") +
  scale_color_manual(name = "distribution", values = c(t_dist = "blue",  normal= "black")) +
  labs(title="Probability density function (pdf) of sample mean given H0",x="sample mean", y="P(sample mean)") +
  geom_polygon(data = rbind(c(mean(cgroup),0),c(dft9[1,1],0),subset(dft9[c(1,3)],t.values<mean(cgroup))), aes(x=t.values, y=dt9), fill="#FFD2D5")
```

Let us explain the rejection with two plots. Both the plots assume that $H_0$ holds. The first one constructs a t-distribution with $n_c-1=9$ degrees of freedom, whose mean is 95 and standard deviation corresponds to $s_c/\sqrt{n_c}$. The probability of observing a sample mean $\bar{x}_c=89.9$ or smaller from the population where $H_0$ holds is relatively high. It corresponds to the area under the left tail of the distribution, which matches the p-value obtained from the one-sided t-test, i.e., 0.14.

```{r conventional treatment explanatory cumulative distribution plot, echo=FALSE}

# the distribution function of t-distribution with 9 degrees of freedom
dftd9 <- data.frame(t.vals=seq(-5,5,0.1),dtd9=pt(seq(-5,5,0.1),df=length(cgroup)-1))

# use the observed sample mean and standard deviation and plot
ggplot(dftd9, aes(x = t.vals, y = dtd9)) + 
  geom_line(col="blue") +
  geom_vline(aes(xintercept = t.value, color="observed"), linetype="dashed") +
  geom_vline(aes(xintercept = qt(0.05,df=9,lower.tail=T), color="needed_to_reject"), linetype="dashed") +
  geom_hline(aes(yintercept = pt(t.value,df=9,lower.tail=T)), color="blue", linetype="dashed") +
  geom_hline(aes(yintercept = 0.05), color="red", linetype="dashed") +
  scale_color_manual(name = "t-value", values = c(observed = "blue",  needed_to_reject= "red")) +
  labs(title="Cumulative distribution function of the t-distribution with 9 degrees of freedom",x="t statistic", y="P(T<=t)")
```

The second plot constructs a cumulative distribution function of the same distribution. The function maps values from the domain of a random variable to their corresponding cumulative probabilities. We observed the t-statistic of -1.15 which maps to the probability of 0.14. In order to reject the null hypothesis with $\alpha=0.05$, we would need to reach at least -1.83.

<!--  In the cumulative distribution function, the p-value does not correspond to the area under the tail but it can be read off on y-axis straightforwardly. -->

### Confidence intervals

```{r conventional treatment confidence interval}
# the upper bound of the confidence interval
paste("The upper bound of the 95%-confidence interval of the coventional treatment sample mean:", c_mean+qt(0.95,df=9)*m_sd)
```

The one-tailed 95% confidence interval will be: 
$$[-\infty,89.9+t_{1-\alpha,n_c-1}\times s_c/\sqrt{n_c}]=[-\infty,89.9+t_{0.95,9}\times 14.02/\sqrt{10}]=[-\infty,98.03]$$
The true value of population mean will be captured in 95% of sampling trials like this. The observation that the 95% confidence interval contains the blood pressure threshold of 95 leads us to the same conclusion as with hypothesis testing: the sample does not provide sufficient evidence to demonstrate the desired effect of the drug. In practice, a larger sample would likely be taken at this stage. 

## A new drug appears, does it meet our expectations?

However, let a new blood pressure drug emerge in the meantime. Physicians have identified a new treatment group of 10 people who received the new drug. The drug is expected to lower blood pressure more effectively than the conventional drug. After a couple of months of treatment (following the same procedure as in the previous conventional group), we need to decide whether the new drug meets the original goal and also, whether it works better than the conventional treatment.

```{r new treatment}
ngroup <- c(71,79,69,98,91,85,89,75,78,80)
paste("Mean blood pressure and standard deviation in the new treatment sample:", mean(ngroup), "and", round(sd(ngroup),2))
```

```{r new treatment histogram, echo=FALSE}
df <- data.frame(treatment=c(rep("conventional",10),rep("new",10)),bp=c(cgroup,ngroup))

# Draw overlaying histogram
ggplot(df, aes(x = bp, fill = treatment)) + 
  geom_histogram(position = "identity", alpha = 0.2, bins = 5) +
  labs(title="Sample histograms",x="Blood pressure", y="Frequency")
```

The new treatment looks promising, but we need to decide it formally. The sample mean $\bar{x}_n$ is 81.5, which is less than $\bar{x}_c$. The histogram above checks whether sample distributions agree with our expectations for both the treatments. It rather confirms our assumptions (no outliers, no multiple modes, etc.). We do not have to consider non-parametric tests without applying assumptions. We will proceed with t-distributions as we did before.

<!--  Alternatively, we may test the assumptions of normality (Kolmogorov–Smirnov or Shapiro–Wilk test) and equal variance (F-test, Levene test), however, samples are small and the tests would likely be passed anyway. What is more, it would be too much detailed for the moment. -->

```{r new treatment sample mean, echo=FALSE}

# probability density function of t-distribution with n-1 degrees of freedom, the given mean and standard deviation
n_mean <- mean(ngroup)
n_sd <- sd(ngroup)
t.values <- seq(min(c_mean,n_mean)-15,max(c_mean,n_mean)+15,0.2)
dft9n <- data.frame(t.values,dt9=dlst(t.values,df=length(cgroup)-1,mu=c_mean,sigma=c_sd/sqrt(length(cgroup))),dt9n=dlst(t.values,df=length(ngroup)-1,mu=n_mean,sigma=n_sd/sqrt(length(ngroup))))

# use the observed sample mean and standard deviation and plot t-distributions
ggplot(dft9n, aes(x = t.values)) + 
  geom_line(aes(y = dt9, color="conventional")) +
  geom_line(aes(y = dt9n, color="new")) +
  geom_ribbon(aes(ymin = 0, ymax = pmin(dt9, dt9n)), fill = "#FFD2D5", alpha = 0.5) +
  geom_vline(aes(xintercept = 85.48, color="black"), linetype="dashed") +
  scale_color_manual(values = c("conventional" = "red", "new" = "blue")) +
  labs(title="Probability density function of sample means",x="sample mean", y="P(sample mean)")

```

When plotting the t-distributions for both the sample means we can see that the new treatment has a large chance to overcome the conventional one, however, as the mean pdfs overlap, the relationship between the treatments can still be opposite. 

<!--  Notice that the area of overlap does not give the probability that the conventional treatment is actually better than the new treatment. The mean of 85.48 is the value where the conventional treatment mean and the new treatment mean show the same probability. The left area corresponds to the probability of event A when the conventional treatment mean is smaller than 85.48 (pt((blood_match-c_mean)/(c_sd/sqrt(sample_size)),sample_size-1)=0.17). The right area gives the probability of event B when the new treatment mean is larger than 85.48 (pt((blood_match-n_mean)/(n_sd/sqrt(sample_size)),sample_size-1,lower.tail=F)=0.1). These events are independent and the sum of their probabilities (the total area of overlap) corresponds to no simple event (P(A ∪ B)=P(A)+P(B) holds for mutually exclusive A and B only). If we multiply these two probabilities, we have the event A ∩ B with probability 0.017. This event implies that the conventional treatment is actually better than the new treatment but it is not the necessary condition for it. The best way to calculate the probability is from the differential distribution of sample means as performed in the t-test below. -->

### Hypothesis testing, one-sample t-test

```{r new treatment two-sample t-test}

t.test(x=ngroup,alternative="less",mu=max_target_mean)
```

Before we will compare both the treatments, we checked whether the new drug fulfills the original goal, reach the mean blood pressure below 95. We work with $H_0$: "the population mean is 95", and $H_a$: "the population mean is smaller than 95". The p-value of 0.0006 suggests that there is only very small probability that the sample as ours may appear by chance if $H_0$ holds, **we reject the null hypothesis** in favor of the alternative one.

### Hypothesis testing, two-sample t-test

Obviously, we will now use a two-sample t-test to compare the treatments. We will additionally assume that the blood pressure variance is equal in both the treatment groups (even though $s_c$ and $s_n$ do not match exactly). This will help us to decide which type of t-test to use and use the pooled t-test.

```{r new treatment one-sample t-test}

t.test(x=cgroup,y=ngroup,var.equal=T,alternative="greater")
```


We work with $H_0$: "the population means are equal, i.e., $\mu_n=\mu_c$", and $H_a$: "the new drug population mean is smaller than the conventional drug population mean, i.e., $\mu_n<\mu_c$".
The p-value of 0.065 suggests that there is around 7% probability that the samples as ours may appear by chance if $H_0$ holds, we cannot reject the null hypothesis in favor of the alternative one at the level of significance 0.05.

Technically, the test formula is:
$$df=n_c+n_n-2=18\;\;\; s_p^2=\frac{(n_c-1)s_c^2+(n_n-1)s_n^2}{df}=\frac{9\times 14.02^2+9\times 9.19^2}{18}=140.5$$
$$t=\frac{\bar{x}_c-\bar{x}_n}{\sqrt{s_p^2(\frac{1}{n_c}+\frac{1}{n_n})}}=\frac{89.9-81.5}{\sqrt{\frac{140.5\times 2}{10}}}=1.58$$
where $df$ is the number of degrees of freedom in our test and $s_p$ is the pooled sample standard deviation. The t-statistic is 1.58, p-value is around 7%, larger than the selected level of significance $\alpha$. We would need to reach t-statistic at least `r round(qt(0.05,18,lower.tail=F),2)` to reject the null hypothesis.

**Further questions and tasks:**

1. propose a similar scenario where a two-tailed test could be applied, how would you change the formulas and graph interpretations above?
2. what happens if we decrease/increase the sample size? explain the influence on statistical testing (technical changes, significance and power of the test),
3. mention as many principal changes in the study design as possible that would require choosing a different statistical test.

# The drug effects and populations known

Now let us assume that both the blood pressure populations are known. In particular, they are normally distributed, the mean blood pressure in the conventional group as well as the new drug group is 90, the equal standard deviations of 12 can be observed in both the populations. In other words, $\mu_c=\mu_n=90$, $\sigma_c=\sigma_n=12$. Let us generate a large number of small samples from both the populations and see how well the t-test works.

```{r generate samples from known populations}
mu_c <- 90
mu_n <- 90
sigma_c <- 12
sigma_n <- 12

## sample size and the number of repeats
sample_size <- 10
reps <- 10000

## generate the samples and run the tests
# is mean in cgroup <95?
tcs <- c() 
pcs <- c()
# is mean in ngroup <95?
tns <- c() 
pns <- c()
# compare cgroup and ngroup
tcns <- c() 
pcns <- c()
for (rep in seq(reps)){
  ## generate two samples with the random normal generator
  cgroup <- rnorm(sample_size,mean=mu_c,sd=sigma_c)
  ngroup <- rnorm(sample_size,mean=mu_n,sd=sigma_n)
  ## compare groups with 95
  ## t-test statistic
  tcs[rep] <- (mean(cgroup)-max_target_mean)/(sd(cgroup)/sqrt(sample_size))
  tns[rep] <- (mean(ngroup)-max_target_mean)/(sd(ngroup)/sqrt(sample_size))
  ## do the same with built in t-test (remember only p-values)
  pcs[rep] <- t.test(x=cgroup,alternative="less",mu=max_target_mean)$p.value
  pns[rep] <- t.test(x=ngroup,alternative="less",mu=max_target_mean)$p.value
  ## compare cgroup and ngroup
  ## t-test statistic
  tcns[rep] <- (mean(cgroup)-mean(ngroup))/(sqrt((sd(cgroup)^2+sd(ngroup)^2)/2)*sqrt(2/sample_size))
  ## do the same with built in t-test (remember only p-values), run two-tailed test this time
  pcns[rep] <- t.test(cgroup,ngroup,alternative = "two.sided",var.equal = TRUE,conf.level = 0.95)$p.value
}
```

## Power of the test and Type II error

Hypotheses tests become only confirmatory now, the truth is known. In the code above, we did two types of t-tests. The first one verifies whether the treatments achieve the mean blood pressure of no more than 95. We run the same test independently for both the treatments. Since we know that $\mu_c=\mu_n=90$ which is clearly less than 95, we also know that the null hypotheses $\mu_c=95$ and $\mu_n=95$ should definitely be rejected against their alternatives $\mu_c<95$ and $\mu_n<95$. Whenever we failed to reject the null hypotheses we made Type II error. The power of t-test is the probability that we correctly reject the null hypotheses.

```{r analyze the t-test outcomes, compare with 95}
## how often will we correctly reject the null hypothesis?
## the power of test
## can be reached in two ways, to compare the p-values with alpha or the t-statistics with the corresponding t-distribution quantile 
thres_05 <- qt(0.05,df=sample_size-1)
## the conventional group
## the same outcome can be reached with: mean(pcs<0.05)
paste("The experimental power of t-test in the conventional group:", mean(tcs<thres_05))
## the new drug group
## the same outcome can be reached with: mean(pns<0.05)
paste("The experimental power of t-test in the new group:", mean(tns<thres_05))
## t-statistic that is expected under ideal conditions when the sample mean and variance agree with the population mean and variance
t_expected <- (mu_c-max_target_mean)/(sigma_c/sqrt(sample_size))
## the real power of the test derived from theory
## shift the distribution function to the left by |t_expected|
paste("The theoretical power of t-test in each group:", pt(thres_05-t_expected,df=sample_size-1))
```

Under the given experimental setting, the power of tests for both the treatments is only a bit more than 30%. The populations are the same, the small difference in the outcomes is due to randomness. As a rule of thumb, statistical experiments should be designed to have a power of around 80%. We will return to this issue later.

```{r t-test distribution plots, echo=FALSE}
## plot the t-statistic distribution for the first two tests and compare them with theory
dft <- data.frame(ts=c(tcs,tns),group=c(rep("conventional",reps),rep("new",reps)))

density_new <- density(dft$ts[dft$group == "new"])

# Create a data frame with the density values for the red group
dft_new_density <- data.frame(
  x = density_new$x,
  y = density_new$y
)

# Subset only the area to the left of thres_05
dft_new_density <- subset(dft_new_density, x <= thres_05)

ggplot(NULL) + 
  geom_density(data=dft,aes(x=ts,color=group)) +
  geom_line(data=data.frame(t.vals=seq(-5,5,0.1)+t_expected,dtd9=dt(seq(-5,5,0.1),df=sample_size-1)),aes(x=t.vals,y=dtd9),linetype="dotted") +
  geom_vline(aes(xintercept = thres_05),linetype="dashed") +
  geom_area(data=dft_new_density, aes(x = x, y = y), fill = "#FFD2D5", alpha = 0.5) +
  labs(title="Experimental and theoretical probability density functions of t-distribution",x="t-statistic", y="P(t-statistic)")

# The interpretation of density plot:
# we know the populations, thus we know that the null hypothesis H_0: "mean=95" does not hold
# the null hypothesis is correctly rejected if the value of t-statistic is smaller than -1.83
# this holds only in about one third of samples
```

The observation can be reinforced with the probability density plot. The power of test corresponds to the area under left tail. You can compare the experimental areas reached for the conventional and new treatment samples and the area under the shifted t-distribution with 9 degrees of freedom shown in the dotted line. The dashed vertical line shows the threshold that leads to rejection of the null hypothesis, the threshold is $t_{0.05,9}=-1.83$.

## Type I error and $\alpha$

The second type of t-tests verifies whether the treatments match in their mean blood pressures. Since we know that $\mu_c=\mu_n=90$, we also know that the null hypotheses $\mu_c=\mu_n$ should not be rejected against its alternative $\mu_c\neq\mu_n$. Whenever we rejected the null hypothesis we made Type I error.

```{r analyze the t-test outcomes, mutually compare the treatments}
## how often will we incorrectly reject the null hypothesis about the identity of population means?
## Type I error, false positive decisions
thres_025 <- qt(0.975,df=2*sample_size-2)
## the same outcome can be reachjed with: mean(pcns<0.05)
paste("The probability of Type I error of the t-test that compares both the groups:", mean(abs(tcns)>thres_025))
```

The Type I error should match the selected significance level $\alpha=0.05$. Quite as expected, we see that the null hypothesis was incorrectly rejected in around 5% of the tests.

```{r two-sample t-test distribution plot, echo=FALSE}
## plot the t-statistic distribution for the comparison between treatments
lower_critical <- qt(0.025, df = 2 * sample_size - 2)
upper_critical <- qt(0.975, df = 2 * sample_size - 2)

# Compute density for the tcns variable
density_data <- density(tcns)

# Create a data frame with the density values
density_df <- data.frame(
  x = density_data$x,
  y = density_data$y
)

# Subset data for left and right tails
left_tail <- subset(density_df, x <= lower_critical)
right_tail <- subset(density_df, x >= upper_critical)

ggplot(NULL) + 
  # Plot the density for tcns
  geom_density(data = data.frame(tcns = tcns), aes(x = tcns), color = "blue") +
  # Vertical lines for critical values
  geom_vline(aes(xintercept = lower_critical), linetype = "dashed", color = "blue") +
  geom_vline(aes(xintercept = upper_critical), linetype = "dashed", color = "blue") +
  # Fill the tail areas
  geom_area(data = left_tail, aes(x = x, y = y), fill = "#FFD2D5", alpha = 0.5) +
  geom_area(data = right_tail, aes(x = x, y = y), fill = "#FFD2D5", alpha = 0.5) +
  # Theoretical t-distribution line
  geom_line(data = data.frame(t.vals = seq(-5, 5, 0.1), 
                              dtd9 = dt(seq(-5, 5, 0.1), df = 2 * sample_size - 2)), 
            aes(x = t.vals, y = dtd9), linetype = "dotted") +
  # Add labels
  labs(title = "Experimental and theoretical probability density functions of t-distribution",
       x = "t-statistic", y = "P(t-statistic)")

# The interpretation of density plot:
# we know the populations, thus we know that the null hypothesis H_0: "means in both the groups are equal" holds, and H_a: "means in both the groups differ" does not hold
# the null hypothesis is incorrectly rejected if the value of t-statistic is smaller than -2.1 or larger than 2.1
# this condition is met in approximately 5% of cases which perfectly matches with the selected significance level alpha 0.05
# the dotted t-distribution with 18 degrees of freedom shows that the emprically generated t-statistics follow the assumed distribution

```

The observation can be reinforced with the probability density plot. In the bold line we can see the experimental density of t-statistics generated through 10,000 sample pairs. The dotted line corresponds to theoretical t-distribution with 18 degrees of freedom. The Type I error corresponds to the area in both the tails generated for quantiles $t_{0.025,18}$ and $t_{0.975,18}$.

**Further questions and tasks:**

1. the power of the test that evaluates whether "the mean blood pressure after treatment is smaller than 95" is relatively low, change the parameters above to increase this power, report when you reach 80%,
2. see what happens with the test when violating assumptions with outliers, inject a severe outlier in the sample and explain the outcomes,
3. violate other assumptions to see what happens (a distribution different from normal one, unequal variances, etc.),
4. show the setting in which the central limit theorem can be applied, gradually change the setting to see what happens with the distribution of sample means.
